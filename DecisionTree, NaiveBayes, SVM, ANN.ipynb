{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTree, NaiveBayes, SVM, ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gvJfTJHavlLF"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denizgurzihin/DecisionTree-NaiveBayes-SVM-ANN/blob/main/DecisionTree%2C%20NaiveBayes%2C%20SVM%2C%20ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbmSZ0QQHkSe"
      },
      "source": [
        "# ***Decision Tree Using Gain Ratio***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj4qaI2oxVhk"
      },
      "source": [
        "***1) With Holdout Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZFNbWnawljx",
        "outputId": "321d7df5-57da-404b-a8a1-63f7fad8c1bd"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn.metrics import *\n",
        "from time import time\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "#DATA.info()\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "for x in range(10):\n",
        "  test_start = time()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=x) # 80% training and 20% test\n",
        "\n",
        "  # Create Decision Tree classifer object\n",
        "  clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "\n",
        "  # Train Decision Tree Classifer\n",
        "  clf = clf.fit(X_train, y_train)\n",
        "\n",
        "  #Predict the response for test dataset\n",
        "  y_pred = clf.predict(X_test)\n",
        "  \n",
        "  accuracy = accuracy + accuracy_score(y_test, y_pred)\n",
        "  f1 = f1 + f1_score(y_test, y_pred, average='weighted')\n",
        "  precision = precision + precision_score(y_test, y_pred, average='weighted')\n",
        "  recall = recall + recall_score(y_test, y_pred, average='weighted')\n",
        "  Confusion_Matrix = Confusion_Matrix + confusion_matrix(y_test, y_pred)\n",
        "  test_finish = time()\n",
        "  timee = timee + test_finish-test_start\n",
        "\n",
        "print(\"Overall accuracy for decision tree with gain ratio and hold out method(10 times) :\", accuracy/10)\n",
        "print(\"Overall f1_score for decision tree with gain ratio and hold out method(10 times) :\", f1/10)\n",
        "print(\"Overall precision_score for decision tree with gain ratio and hold out method(10 times) :\", precision/10)\n",
        "print(\"Overall recall_score for decision tree with gain ratio and hold out method(10 times) :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix/10)\n",
        "\n",
        "print(\"Overall time needed for decision tree with gain ratio and hold out method(10 times) :\", ((timee/10)*10*10*10), \" miliseconds\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for decision tree with gain ratio and hold out method(10 times) : 0.7381018518518518\n",
            "Overall f1_score for decision tree with gain ratio and hold out method(10 times) : 0.7432142648062039\n",
            "Overall precision_score for decision tree with gain ratio and hold out method(10 times) : 0.7494627752881005\n",
            "Overall recall_score for decision tree with gain ratio and hold out method(10 times) : 0.7381018518518518\n",
            "       Confusion Matrix : \n",
            "[[172.   78.   84.8  15.1]\n",
            " [ 99.4 704.2  36.9  28.3]\n",
            " [103.5  34.7 691.5  28.9]\n",
            " [ 13.1  21.1  21.9  26.6]]\n",
            "Overall time needed for decision tree with gain ratio and hold out method(10 times) : 34.22291278839111  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E825cdQrHP5T"
      },
      "source": [
        "***2) With K Fold Cross-validation Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsMmnvkqHUpz",
        "outputId": "82e93d3c-dd3d-4319-ae6f-2baff50cffc2"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import *\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "scoring = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
        "\n",
        "for i in range(10):\n",
        "  test_start = time()\n",
        "  kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state = i )\n",
        "  model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "\n",
        "  results = model_selection.cross_validate(model, X, y, cv=kfold, scoring=scoring)\n",
        "  accuracy = accuracy + results['test_accuracy'].mean()\n",
        "  f1 = f1 + results['test_f1_weighted'].mean()\n",
        "  precision = precision + results['test_precision_weighted'].mean()\n",
        "  recall = recall + results['test_recall_weighted'].mean()\n",
        "  test_finish = time()\n",
        "  timee = timee + test_finish-test_start\n",
        "\n",
        "  y_pred = cross_val_predict(model, X, y, cv=kfold)\n",
        "  Confusion_Matrix = Confusion_Matrix + confusion_matrix(y, y_pred)\n",
        "\n",
        "print(\"Overall accuracy for decision tree with gain ratio and K Fold cross valdiation(10 times) :\", accuracy/10)\n",
        "print(\"Overall f1_score for decision tree with gain ratio and K Fold cross valdiation(10 times) :\", f1/10)\n",
        "print(\"Overall precision_score for decision tree with gain ratio and K Fold cross valdiation(10 times) :\", precision/10)\n",
        "print(\"Overall recall_score for decision tree with gain ratio and K Fold cross valdiation(10 times) :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix/10)\n",
        "\n",
        "print(\"Overall time needed for decision tree with gain ratio and K Fold cross valdiation(10 times) :\", ((timee/10)*10*10*10), \" miliseconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for decision tree with gain ratio and K Fold cross valdiation(10 times) : 0.7397314814814815\n",
            "Overall f1_score for decision tree with gain ratio and K Fold cross valdiation(10 times) : 0.7439006327894975\n",
            "Overall precision_score for decision tree with gain ratio and K Fold cross valdiation(10 times) : 0.7489958833974054\n",
            "Overall recall_score for decision tree with gain ratio and K Fold cross valdiation(10 times) : 0.7397314814814815\n",
            "       Confusion Matrix : \n",
            "[[ 868.6  408.   433.3   76.1]\n",
            " [ 464.8 3509.4  185.4  146.4]\n",
            " [ 508.7  174.4 3469.4  147.5]\n",
            " [  70.    98.8  104.8  134.4]]\n",
            "Overall time needed for decision tree with gain ratio and K Fold cross valdiation(10 times) : 154.81994152069092  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ6vQy58Ijls"
      },
      "source": [
        " ***3) Bagging with cross validation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEy2WP9FJRKD",
        "outputId": "b13af9e9-2b0c-4350-baec-dcffa5a7813a"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "x = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "scoring = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
        "\n",
        "for i in range(10):\n",
        "  test_start = time()\n",
        "  kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=i)\n",
        "  dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "  model = BaggingClassifier(base_estimator=dt, random_state=i)\n",
        "\n",
        "  results = model_selection.cross_validate(model, X, y, cv=kfold, scoring=scoring)\n",
        "\n",
        "  accuracy = accuracy + results['test_accuracy'].mean()\n",
        "  f1 = f1 + results['test_f1_weighted'].mean()\n",
        "  precision = precision + results['test_precision_weighted'].mean()\n",
        "  recall = recall + results['test_recall_weighted'].mean()\n",
        "  test_finish = time()\n",
        "  timee = timee + test_finish-test_start\n",
        "\n",
        "  y_pred = cross_val_predict(model, X, y, cv=kfold)\n",
        "  Confusion_Matrix = Confusion_Matrix + confusion_matrix(y, y_pred)\n",
        "\n",
        "\n",
        "print(\"Overall accuracy for decision tree with gain ratio and Bagging with K-Fold Cross Validation :\", accuracy/10)\n",
        "print(\"Overall f1_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation :\", f1/10)\n",
        "print(\"Overall precision_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation :\", precision/10)\n",
        "print(\"Overall recall_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix/10)\n",
        "\n",
        "print(\"Overall time needed for decision tree with gain ratio and Bagging with K-Fold Cross Validation :\", ((timee/10)*10*10*10), \" miliseconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for decision tree with gain ratio and Bagging with K-Fold Cross Validation : 0.7904722222222222\n",
            "Overall f1_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation : 0.7885554846696445\n",
            "Overall precision_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation : 0.7880436538169946\n",
            "Overall recall_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation : 0.7904722222222222\n",
            "       Confusion Matrix : \n",
            "[[ 982.5  364.4  400.2   38.9]\n",
            " [ 377.1 3752.9  102.6   73.4]\n",
            " [ 414.6  125.9 3685.    74.5]\n",
            " [  63.   115.7  112.6  116.7]]\n",
            "Overall time needed for decision tree with gain ratio and Bagging with K-Fold Cross Validation : 1957.092261314392  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N2jwqGfIjYz"
      },
      "source": [
        "***4) Boosting with cross validation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc8HAqBsJRgI",
        "outputId": "894ff4f3-7a20-456e-e5a5-ee7fec6a9ee9"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "x = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "scoring = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
        "\n",
        "for i in range(10):\n",
        "  test_start = time()\n",
        "  kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=i)\n",
        "  dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "  model = AdaBoostClassifier(base_estimator= dt)\n",
        "\n",
        "  results = model_selection.cross_validate(model, X, y, cv=kfold, scoring=scoring)\n",
        "  test_finish = time()\n",
        "  \n",
        "  accuracy = accuracy + results['test_accuracy'].mean()\n",
        "  f1 = f1 + results['test_f1_weighted'].mean()\n",
        "  precision = precision + results['test_precision_weighted'].mean()\n",
        "  recall = recall + results['test_recall_weighted'].mean()\n",
        "  timee = timee + test_finish-test_start\n",
        "\n",
        "  y_pred = cross_val_predict(model, X, y, cv=kfold)\n",
        "  Confusion_Matrix = Confusion_Matrix + confusion_matrix(y, y_pred)\n",
        "\n",
        "print(\"Overall accuracy for decision tree with Boosting with K-Fold Cross Validation :\", accuracy/10)\n",
        "print(\"Overall f1_score for decision tree with Boosting with K-Fold Cross Validation :\", f1/10)\n",
        "print(\"Overall precision_score for decision tree with Boosting with K-Fold Cross Validation :\", precision/10)\n",
        "print(\"Overall recall_score for decision tree with Boosting with K-Fold Cross Validation :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix/10)\n",
        "\n",
        "print(\"Overall time needed for decision tree with Boosting with K-Fold Cross Validation :\", ((timee/10)*10*10*10), \" miliseconds\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for decision tree with Boosting with K-Fold Cross Validation : 0.7430000000000001\n",
            "Overall f1_score for decision tree with Boosting with K-Fold Cross Validation : 0.7471670069283624\n",
            "Overall precision_score for decision tree with Boosting with K-Fold Cross Validation : 0.7526061857456584\n",
            "Overall recall_score for decision tree with Boosting with K-Fold Cross Validation : 0.7430000000000001\n",
            "       Confusion Matrix : \n",
            "[[ 880.7  409.3  419.    77. ]\n",
            " [ 451.5 3538.6  174.4  141.5]\n",
            " [ 508.6  168.7 3478.6  144.1]\n",
            " [  69.2   95.7  110.8  132.3]]\n",
            "Overall time needed for decision tree with Boosting with K-Fold Cross Validation : 405.2299499511719  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u3H5pJEXQwP"
      },
      "source": [
        "# ***Decision Tree Using Gini Index***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irDY88G3XX9r"
      },
      "source": [
        "***1) With Holdout Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2I69GSPFBOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cebf26-a280-420a-98e8-2b8254fb4a83"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "\n",
        "X = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "for x in range(10):\n",
        "  test_start = time()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=x) # 80% training and 20% test\n",
        "\n",
        "  # Create Decision Tree classifer object\n",
        "  clf = DecisionTreeClassifier(criterion=\"gini\")\n",
        "\n",
        "  # Train Decision Tree Classifer\n",
        "  clf = clf.fit(X_train, y_train)\n",
        "\n",
        "  #Predict the response for test dataset\n",
        "  y_pred = clf.predict(X_test)\n",
        "  \n",
        "  accuracy = accuracy + metrics.accuracy_score(y_test, y_pred)\n",
        "  f1 = f1 + f1_score(y_test, y_pred, average='weighted')\n",
        "  precision = precision + precision_score(y_test, y_pred, average='weighted')\n",
        "  recall = recall + recall_score(y_test, y_pred, average='weighted')\n",
        "  Confusion_Matrix = Confusion_Matrix + confusion_matrix(y_test, y_pred)\n",
        "  test_finish = time()\n",
        "  timee = timee + test_finish-test_start\n",
        "\n",
        "print(\"Overall accuracy for decision tree with gini index and hold out method(10 times) :\", accuracy/10)\n",
        "print(\"Overall f1_score for decision tree with gini index and hold out method(10 times) :\", f1/10)\n",
        "print(\"Overall precision_score for decision tree with gini index and hold out method(10 times) :\", precision/10)\n",
        "print(\"Overall recall_score for decision tree with gini index and hold out method(10 times) :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix/10)\n",
        "\n",
        "print(\"Overall time needed for decision tree with gini index and hold out method(10 times) :\", ((timee/10)*10*10*10), \" miliseconds\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for decision tree with gini index and hold out method(10 times) : 0.7405092592592593\n",
            "Overall f1_score for decision tree with gini index and hold out method(10 times) : 0.7454981060893098\n",
            "Overall precision_score for decision tree with gini index and hold out method(10 times) : 0.751649111111863\n",
            "Overall recall_score for decision tree with gini index and hold out method(10 times) : 0.7405092592592593\n",
            "       Confusion Matrix : \n",
            "[[171.6  75.7  88.   14.6]\n",
            " [ 97.3 703.1  38.9  29.5]\n",
            " [102.8  30.4 697.6  27.8]\n",
            " [ 13.3  20.9  21.3  27.2]]\n",
            "Overall time needed for decision tree with gini index and hold out method(10 times) : 31.38277530670166  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e6TD8g5Xcc0"
      },
      "source": [
        "***2) With K Fold Cross-validation Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pEA7PATXqS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a4af2f-7de0-4b3d-afa0-6e0b159fc373"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import *\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "scoring = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
        "\n",
        "for i in range(10):\n",
        "  test_start = time()\n",
        "  kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state = i )\n",
        "  model = DecisionTreeClassifier(criterion=\"gini\")\n",
        "\n",
        "  results = model_selection.cross_validate(model, X, y, cv=kfold, scoring=scoring)\n",
        "  accuracy = accuracy + results['test_accuracy'].mean()\n",
        "  f1 = f1 + results['test_f1_weighted'].mean()\n",
        "  precision = precision + results['test_precision_weighted'].mean()\n",
        "  recall = recall + results['test_recall_weighted'].mean()\n",
        "  test_finish = time()\n",
        "  timee = timee + test_finish-test_start\n",
        "\n",
        "  y_pred = cross_val_predict(model, X, y, cv=kfold)\n",
        "  Confusion_Matrix = Confusion_Matrix + confusion_matrix(y, y_pred)\n",
        "\n",
        "print(\"Overall accuracy for decision tree with gini index and K Fold cross valdiation(10 times) :\", accuracy/10)\n",
        "print(\"Overall f1_score for decision tree with gini index and K Fold cross valdiation(10 times) :\", f1/10)\n",
        "print(\"Overall precision_score for decision tree with gini index and K Fold cross valdiation(10 times) :\", precision/10)\n",
        "print(\"Overall recall_score for decision tree with gini index and K Fold cross valdiation(10 times) :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix/10)\n",
        "\n",
        "print(\"Overall time needed for decision tree with gini index and K Fold cross valdiation(10 times) :\", ((timee/10)*10*10*10), \" miliseconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for decision tree with gini index and K Fold cross valdiation(10 times) : 0.7391111111111112\n",
            "Overall f1_score for decision tree with gini index and K Fold cross valdiation(10 times) : 0.7434713429090583\n",
            "Overall precision_score for decision tree with gini index and K Fold cross valdiation(10 times) : 0.7488503997491684\n",
            "Overall recall_score for decision tree with gini index and K Fold cross valdiation(10 times) : 0.7391111111111112\n",
            "       Confusion Matrix : \n",
            "[[ 880.4  397.6  434.6   73.4]\n",
            " [ 455.6 3510.5  186.7  153.2]\n",
            " [ 505.7  177.  3469.4  147.9]\n",
            " [  68.9  104.5  105.4  129.2]]\n",
            "Overall time needed for decision tree with gini index and K Fold cross valdiation(10 times) : 139.58969116210938  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDDNXm7DXefg"
      },
      "source": [
        " ***3) With Bagging Ensemble Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9qkoTw9XrFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25dc73f9-a8e6-445c-8d0c-4c206a2bce46"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "x = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "scoring = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
        "\n",
        "for i in range(10):\n",
        "  test_start = time()\n",
        "  kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=i)\n",
        "  dt = DecisionTreeClassifier(criterion=\"gini\")\n",
        "  model = BaggingClassifier(base_estimator=dt, random_state=i)\n",
        "\n",
        "  results = model_selection.cross_validate(model, X, y, cv=kfold, scoring=scoring)\n",
        "  test_finish = time()\n",
        "\n",
        "  accuracy = accuracy + results['test_accuracy'].mean()\n",
        "  f1 = f1 + results['test_f1_weighted'].mean()\n",
        "  precision = precision + results['test_precision_weighted'].mean()\n",
        "  recall = recall + results['test_recall_weighted'].mean()\n",
        "  timee = timee + test_finish-test_start\n",
        "\n",
        "  y_pred = cross_val_predict(model, X, y, cv=kfold)\n",
        "  Confusion_Matrix = Confusion_Matrix + confusion_matrix(y, y_pred)\n",
        "\n",
        "\n",
        "print(\"Overall accuracy for decision tree with gain ratio and Bagging with K-Fold Cross Validation :\", accuracy/10)\n",
        "print(\"Overall f1_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation :\", f1/10)\n",
        "print(\"Overall precision_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation :\", precision/10)\n",
        "print(\"Overall recall_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix/10)\n",
        "\n",
        "print(\"Overall time needed for decision tree with gain ratio and Bagging with K-Fold Cross Validation :\", ((timee/10)*10*10*10), \" miliseconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for decision tree with gain ratio and Bagging with K-Fold Cross Validation : 0.7885833333333333\n",
            "Overall f1_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation : 0.7869335159094929\n",
            "Overall precision_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation : 0.7865808012341375\n",
            "Overall recall_score for decision tree with gain ratio and Bagging with K-Fold Cross Validation : 0.7885833333333333\n",
            "       Confusion Matrix : \n",
            "[[ 983.1  364.7  398.    40.2]\n",
            " [ 380.6 3742.4  105.1   77.9]\n",
            " [ 422.1  123.2 3679.    75.7]\n",
            " [  66.6  114.6  114.6  112.2]]\n",
            "Overall time needed for decision tree with gain ratio and Bagging with K-Fold Cross Validation : 1714.1935586929321  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MnbOgL8XgMZ"
      },
      "source": [
        "***4) With Boosting Ensemble Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BSrkR7vXrvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e749bc-4b76-42c6-9c45-3556a02a2dfc"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "x = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "scoring = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
        "\n",
        "for i in range(10):\n",
        "  test_start = time()\n",
        "\n",
        "  kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=i)\n",
        "  dt = DecisionTreeClassifier(criterion=\"gini\")\n",
        "  model = AdaBoostClassifier(base_estimator= dt, n_estimators=100)\n",
        "  results = model_selection.cross_validate(model, X, y, cv=kfold, scoring=scoring)\n",
        "  test_finish = time()\n",
        "  \n",
        "  accuracy = accuracy + results['test_accuracy'].mean()\n",
        "  f1 = f1 + results['test_f1_weighted'].mean()\n",
        "  precision = precision + results['test_precision_weighted'].mean()\n",
        "  recall = recall + results['test_recall_weighted'].mean()\n",
        "  \n",
        "  timee = timee + test_finish-test_start\n",
        "\n",
        "  y_pred = cross_val_predict(model, X, y, cv=kfold)\n",
        "  Confusion_Matrix = Confusion_Matrix + confusion_matrix(y, y_pred)\n",
        "\n",
        "print(\"Overall accuracy for decision tree with Boosting with K-Fold Cross Validation :\", accuracy/10)\n",
        "print(\"Overall f1_score for decision tree with Boosting with K-Fold Cross Validation :\", f1/10)\n",
        "print(\"Overall precision_score for decision tree with Boosting with K-Fold Cross Validation :\", precision/10)\n",
        "print(\"Overall recall_score for decision tree with Boosting with K-Fold Cross Validation :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix/10)\n",
        "\n",
        "print(\"Overall time needed for decision tree with Boosting with K-Fold Cross Validation :\", ((timee/10)*10*10*10), \" miliseconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for decision tree with Boosting with K-Fold Cross Validation : 0.7454166666666667\n",
            "Overall f1_score for decision tree with Boosting with K-Fold Cross Validation : 0.7493488450055377\n",
            "Overall precision_score for decision tree with Boosting with K-Fold Cross Validation : 0.7544456426944691\n",
            "Overall recall_score for decision tree with Boosting with K-Fold Cross Validation : 0.7454166666666667\n",
            "       Confusion Matrix : \n",
            "[[ 889.5  390.7  437.5   68.3]\n",
            " [ 460.7 3546.5  168.   130.8]\n",
            " [ 525.8  165.  3473.4  135.8]\n",
            " [  62.7  109.   103.3  133. ]]\n",
            "Overall time needed for decision tree with Boosting with K-Fold Cross Validation : 326.5333414077759  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx87-PMTF-oW"
      },
      "source": [
        "# ***Naive Bayes***\n",
        "\n",
        "\n",
        "\n",
        "***1) With Holdout Method***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aFW0ApdFKvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e109c92b-c3e0-4fb6-8475-0bce024bccdb"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split  # Import train_test_split function\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from time import time\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13',\n",
        "             'att14', 'att15', 'att16', 'label']\n",
        "DATA = pd.read_csv('Final_Data.csv', header=None, names=col_names)\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12',\n",
        "                'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols]  # Features\n",
        "y = DATA.label  # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "for x in range(10):\n",
        "    test_start = time()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=x)  # 80% training and 20% test\n",
        "\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train.ravel())\n",
        "    y_pred = gnb.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy + metrics.accuracy_score(y_test, y_pred)\n",
        "    f1 = f1 + f1_score(y_test, y_pred, average='weighted')\n",
        "    precision = precision + precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall + recall_score(y_test, y_pred, average='weighted')\n",
        "    Confusion_Matrix = Confusion_Matrix + confusion_matrix(y_test, y_pred)\n",
        "    test_finish = time()\n",
        "    timee = timee + test_finish-test_start\n",
        "\n",
        "print(\"Overall accuracy for Naive Bayes with hold out method :\", accuracy/10)\n",
        "print(\"Overall f1_score for Naive Bayes with hold out method :\", f1/10)\n",
        "print(\"Overall precision_score for Naive Bayes with hold out method :\", precision/10)\n",
        "print(\"Overall recall_score for Naive Bayes with hold out method :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix/10)\n",
        "\n",
        "print(\"Overall time needed for Naive Bayes with hold out method :\", ((timee/10)*10*10*10), \" miliseconds\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for Naive Bayes with hold out method : 0.7819907407407408\n",
            "Overall f1_score for Naive Bayes with hold out method : 0.729055644026288\n",
            "Overall precision_score for Naive Bayes with hold out method : 0.7190577152364745\n",
            "Overall recall_score for Naive Bayes with hold out method : 0.7819907407407408\n",
            "       Confusion Matrix : \n",
            "[[ 51.7 140.8 157.4   0. ]\n",
            " [ 14.6 823.8  30.4   0. ]\n",
            " [ 19.4  25.6 813.6   0. ]\n",
            " [ 16.5  26.6  39.6   0. ]]\n",
            "Overall time needed for Naive Bayes with hold out method : 16.830778121948242  miliseconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipiR9Rx-r6P7"
      },
      "source": [
        "***2) With K-fold Cross Validation Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-B3RuvhFKxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6862a1-8804-467b-e883-0d412d0024e5"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from time import time\n",
        "\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "DATA = pd.read_csv('Final_Data.csv', header=None, names=col_names)\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "scoring = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
        "\n",
        "for x in range (10):\n",
        "    test_start = time()\n",
        "    kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=x)\n",
        "    gnb = GaussianNB()\n",
        "\n",
        "    results = model_selection.cross_validate(gnb, X, y, cv=kfold, scoring=scoring)\n",
        "    accuracy = accuracy + results['test_accuracy'].mean()\n",
        "    f1 = f1 + results['test_f1_weighted'].mean()\n",
        "    precision = precision + results['test_precision_weighted'].mean()\n",
        "    recall = recall + results['test_recall_weighted'].mean()\n",
        "    test_finish = time()\n",
        "    timee = timee + test_finish - test_start\n",
        "\n",
        "    y_pred = cross_val_predict(gnb, X, y, cv=kfold)\n",
        "    Confusion_Matrix = Confusion_Matrix + confusion_matrix(y, y_pred)\n",
        "\n",
        "print(\"Overall accuracy for Naive Bayes with k-fold cross validation :\", accuracy / 10)\n",
        "print(\"Overall f1_score for Naive Bayes with k-fold cross validation :\", f1 / 10)\n",
        "print(\"Overall precision_score for Naive Bayes with k-fold cross validation :\", precision / 10)\n",
        "print(\"Overall recall_score for Naive Bayes with k-fold cross validation :\", recall / 10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix / 10)\n",
        "\n",
        "print(\"Overall time needed for Naive Bayes with k-fold cross validation :\", ((timee / 10) * 10 * 10 * 10), \" miliseconds\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for Naive Bayes with k-fold cross validation : 0.7802222222222223\n",
            "Overall f1_score for Naive Bayes with k-fold cross validation : 0.7270947945460494\n",
            "Overall precision_score for Naive Bayes with k-fold cross validation : 0.718425775976114\n",
            "Overall recall_score for Naive Bayes with k-fold cross validation : 0.7802222222222223\n",
            "       Confusion Matrix : \n",
            "[[ 269.9  733.2  782.9    0. ]\n",
            " [  73.6 4097.3  135.1    0. ]\n",
            " [ 102.6  138.2 4059.2    0. ]\n",
            " [  77.5  142.2  188.3    0. ]]\n",
            "Overall time needed for Naive Bayes with k-fold cross validation : 120.38891315460205  miliseconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_73UFGg_y1A"
      },
      "source": [
        "***3) With Bagging Ensemble Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDtgX7xzFK0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8434c7cb-83ef-443a-e4c1-18551a5b9732"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from time import time\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13',\n",
        "             'att14', 'att15', 'att16', 'label']\n",
        "DATA = pd.read_csv('Final_Data.csv', header=None, names=col_names)\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12',\n",
        "                'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols]  # Features\n",
        "y = DATA.label  # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "for x in range(10):\n",
        "    test_start = time()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=x)  # 80% training and 20% test\n",
        "    gnb = GaussianNB()\n",
        "    model = BaggingClassifier(base_estimator=gnb, random_state=x)\n",
        "\n",
        "    model = model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy + metrics.accuracy_score(y_test, y_pred)\n",
        "    f1 = f1 + f1_score(y_test, y_pred, average='weighted')\n",
        "    precision = precision + precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall + recall_score(y_test, y_pred, average='weighted')\n",
        "    Confusion_Matrix = Confusion_Matrix + confusion_matrix(y_test, y_pred)\n",
        "    test_finish = time()\n",
        "    timee = timee + test_finish - test_start\n",
        "\n",
        "print(\"Overall accuracy for Naive Bayes with Bagging Ensemble Method :\", accuracy / 10)\n",
        "print(\"Overall f1_score for Naive Bayes with Bagging Ensemble Method :\", f1 / 10)\n",
        "print(\"Overall precision_score for Naive Bayes with Bagging Ensemble Method :\", precision / 10)\n",
        "print(\"Overall recall_score for Naive Bayes with Bagging Ensemble Method :\", recall / 10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix / 10)\n",
        "\n",
        "print(\"Overall time needed for Naive Bayes with Bagging Ensemble Method :\", ((timee / 10) * 10 * 10 * 10), \" miliseconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for Naive Bayes with Bagging Ensemble Method : 0.7819444444444443\n",
            "Overall f1_score for Naive Bayes with Bagging Ensemble Method : 0.7286495311660636\n",
            "Overall precision_score for Naive Bayes with Bagging Ensemble Method : 0.7192605946964935\n",
            "Overall recall_score for Naive Bayes with Bagging Ensemble Method : 0.7819444444444443\n",
            "       Confusion Matrix : \n",
            "[[ 51.1 141.5 157.3   0. ]\n",
            " [ 14.5 824.3  30.    0. ]\n",
            " [ 18.8  26.2 813.6   0. ]\n",
            " [ 16.2  27.1  39.4   0. ]]\n",
            "Overall time needed for Naive Bayes with Bagging Ensemble Method : 92.2642707824707  miliseconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjqKcY0qFg-P"
      },
      "source": [
        "***4) With Boosting Ensemble Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTMt2ZCDFXQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5ff884-c32a-405a-b813-088fd7a55a98"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from time import time\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13',\n",
        "             'att14', 'att15', 'att16', 'label']\n",
        "DATA = pd.read_csv('Final_Data.csv', header=None, names=col_names)\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12',\n",
        "                'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols]  # Features\n",
        "y = DATA.label  # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "test_start = time()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # 80% training and 20% test\n",
        "\n",
        "gnb = GaussianNB()\n",
        "model = AdaBoostClassifier(base_estimator=gnb, random_state=0, algorithm='SAMME')\n",
        "model = model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "test_finish = time()\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "timee = timee + test_finish-test_start\n",
        "\n",
        "print(\"Overall accuracy for Naive Bayes with Boosting Ensemble Method :\", accuracy)\n",
        "print(\"Overall f1_score for Naive Bayes with Boosting Ensemble Method :\", f1)\n",
        "print(\"Overall precision_score for Naive Bayes with Boosting Ensemble Method :\", precision)\n",
        "print(\"Overall recall_score for Naive Bayes with Boosting Ensemble Method :\", recall)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "\n",
        "print(\"Overall time needed for Naive Bayes with Boosting Ensemble Method :\", ((timee)*10*10*10), \" miliseconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for Naive Bayes with Boosting Ensemble Method : 0.7893518518518519\n",
            "Overall f1_score for Naive Bayes with Boosting Ensemble Method : 0.7507747892816242\n",
            "Overall precision_score for Naive Bayes with Boosting Ensemble Method : 0.7703745641302338\n",
            "Overall recall_score for Naive Bayes with Boosting Ensemble Method : 0.7893518518518519\n",
            "       Confusion Matrix : \n",
            "[[ 89 137 135   0]\n",
            " [ 31 801  16   0]\n",
            " [ 33  24 813   0]\n",
            " [ 19  25  35   2]]\n",
            "Overall time needed for Naive Bayes with Boosting Ensemble Method : 171.62561416625977  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ41C0kgO9MD"
      },
      "source": [
        "# ***SVM***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq4ZY_pXYiW4"
      },
      "source": [
        "***1) SVM With Holdout Method***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bRBXqE3Yn7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73bc2047-c206-483a-bf23-594ca23045f9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.svm import SVC\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "#DATA.info()\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "for x in range(10):\n",
        "  test_start = time()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=x) # 80% training and 20% test\n",
        "\n",
        "  # Create Decision Tree classifer object\n",
        "  model = SVC()\n",
        "\n",
        "  # Train Decision Tree Classifer\n",
        "  model = model.fit(X_train, y_train)\n",
        "\n",
        "  #Predict the response for test dataset\n",
        "  y_pred = model.predict(X_test)\n",
        "  \n",
        "  accuracy = accuracy + accuracy_score(y_test, y_pred)\n",
        "  f1 = f1 + f1_score(y_test, y_pred, average='weighted')\n",
        "  precision = precision + precision_score(y_test, y_pred, average='weighted')\n",
        "  recall = recall + recall_score(y_test, y_pred, average='weighted')\n",
        "  Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
        "  test_finish = time()\n",
        "  timee = timee + test_finish-test_start\n",
        "\n",
        "print(\"Overall accuracy for SVM with hold out method(10 times) :\", accuracy/10)\n",
        "print(\"Overall f1_score for SVM with hold out method(10 times) :\", f1/10)\n",
        "print(\"Overall precision_score for SVM with hold out method(10 times) :\", precision/10)\n",
        "print(\"Overall recall_score for SVM with hold out method(10 times) :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "\n",
        "print(\"Overall time needed for SVM with hold out method(10 times) :\", ((timee/10)*10*10*10), \" miliseconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy for SVM with hold out method(10 times) : 0.8603703703703702\n",
            "Overall f1_score for SVM with hold out method(10 times) : 0.8551754548954541\n",
            "Overall precision_score for SVM with hold out method(10 times) : 0.8582395760064058\n",
            "Overall recall_score for SVM with hold out method(10 times) : 0.8603703703703702\n",
            "       Confusion Matrix : \n",
            "[[222  53  63   1]\n",
            " [ 44 811   3   6]\n",
            " [ 62   9 798   0]\n",
            " [ 24  16  20  28]]\n",
            "Overall time needed for SVM with hold out method(10 times) : 2452.696180343628  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JLxMUewZxrf"
      },
      "source": [
        "***2) SVM With K-Fold Cross Validation Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qdRyZU4TkNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78195051-0504-4a15-c63d-a943e4130343"
      },
      "source": [
        "import pandas as pd\n",
        "from time import time\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import *\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "scoring = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
        "\n",
        "test_start = time()\n",
        "kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state = 100 )\n",
        "model = SVC()\n",
        "results = model_selection.cross_validate(model, X, y, cv=kfold, scoring=scoring)\n",
        "test_finish = time()\n",
        "\n",
        "accuracy = results['test_accuracy'].mean()\n",
        "f1 = results['test_f1_weighted'].mean()\n",
        "precision = results['test_precision_weighted'].mean()\n",
        "recall = results['test_recall_weighted'].mean()\n",
        "timee = test_finish-test_start\n",
        "\n",
        "y_pred = cross_val_predict(model, X, y, cv=kfold)\n",
        "Confusion_Matrix = Confusion_Matrix + confusion_matrix(y, y_pred)\n",
        "\n",
        "print(\"Accuracy for SVM with K-Fold cross validation:\", accuracy)\n",
        "print(\"F1_score for SVM with K-Fold cross validation:\", f1)\n",
        "print(\"Precision_score for SVM with K-Fold cross validation:\", precision)\n",
        "print(\"Recall_score for SVM with K-Fold cross validation:\", recall)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "\n",
        "print(\"Time needed for SVM with K-Fold cross validation:\", ((timee)*10*10*10), \" miliseconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "Overall accuracy for SVM with K-Fold cross validation: 0.8613888888888889\n",
            "Overall f1_score for SVM with K-Fold cross validation: 0.8556676588911707\n",
            "Overall precision_score for SVM with K-Fold cross validation: 0.8586577800895476\n",
            "Overall recall_score for SVM with K-Fold cross validation: 0.8613888888888889\n",
            "       Confusion Matrix : \n",
            "[[2284  556  726    6]\n",
            " [ 458 8062   62   30]\n",
            " [ 510   90 7980   20]\n",
            " [ 200  148  188  280]]\n",
            "Overall time needed for SVM with K-Fold cross validation: 11407.729387283325  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J618_xlSTAP-"
      },
      "source": [
        "***3) SVM Bagging With Holdout Method***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa2-ZWhkTTir",
        "outputId": "e7f85bac-c0d3-4958-bba8-70ac099efb32"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import *\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "\n",
        "test_start = time()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10) # 80% training and 20% test\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "model = BaggingClassifier(base_estimator=SVC(), n_estimators=20, random_state=0)\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "test_finish = time()  \n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
        "timee = test_finish-test_start\n",
        "\n",
        "print(\"Accuracy for SVM with Bagging implemented with Hold Out method :\", accuracy)\n",
        "print(\"F1_score for SVM with Bagging implemented with Hold Out method :\", f1)\n",
        "print(\"Precision_score for SVM with Bagging implemented with Hold Out method :\", precision)\n",
        "print(\"Recall_score for SVM with Bagging implemented with Hold Out method :\", recall)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "\n",
        "print(\"Time needed for SVM with Bagging implemented with Hold Out method :\", ((timee)*10*10*10), \" miliseconds\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for SVM with Bagging implemented with Hold Out method : 0.8555555555555555\n",
            "F1_score for SVM with Bagging implemented with Hold Out method : 0.8497112893830099\n",
            "Precision_score for SVM with Bagging implemented with Hold Out method : 0.8523607419395607\n",
            "Recall_score for SVM with Bagging implemented with Hold Out method : 0.8555555555555555\n",
            "       Confusion Matrix : \n",
            "[[244  60  83   1]\n",
            " [ 57 796   5   3]\n",
            " [ 42   8 778   1]\n",
            " [ 20  17  15  30]]\n",
            "Time needed for SVM with Bagging implemented with Hold Out method : 23194.76342201233  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4T5JePcTa6b"
      },
      "source": [
        "***4) SVM Boosting With Holdout Method***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjiarlzpUdJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba5b5c9-d364-49b6-82ed-f20514bb56e7"
      },
      "source": [
        "import pandas as pd\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "\n",
        "test_start = time()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 10) # 80% training and 20% test\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "model = AdaBoostClassifier(base_estimator=SVC(probability=True), n_estimators=1, random_state= 100)\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "test_finish = time()  \n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
        "timee = test_finish-test_start\n",
        "\n",
        "print(\"Accuracy for SVM with Boosting implemented with Hold Out method :\", accuracy)\n",
        "print(\"F1_score for SVM with Boosting implemented with Hold Out method :\", f1)\n",
        "print(\"Precision_score for SVM with Boosting implemented with Hold Out method :\", precision)\n",
        "print(\"Recall_score for SVM with Boosting implemented with Hold Out method :\", recall)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "\n",
        "print(\"Time needed for SVM with Boosting implemented with Hold Out method :\", ((timee)*10*10*10), \" miliseconds\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for SVM with Boosting implemented with Hold Out method : 0.8074074074074075\n",
            "F1_score for SVM with Boosting implemented with Hold Out method : 0.8099544386965715\n",
            "Precision_score for SVM with Boosting implemented with Hold Out method : 0.8168348589701964\n",
            "Recall_score for SVM with Boosting implemented with Hold Out method : 0.8074074074074075\n",
            "       Confusion Matrix : \n",
            "[[263  72  49   4]\n",
            " [ 93 758   4   6]\n",
            " [ 88  16 700  25]\n",
            " [ 33  18   8  23]]\n",
            "Time needed for SVM with Boosting implemented with Hold Out method : 31487.324714660645  miliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuh166A8PKpT"
      },
      "source": [
        "# ***Artificial Neural Networks (Single Hidden Layer)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xEguNBZPhH7"
      },
      "source": [
        "**1) Single Hidden Layer ANN**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkwYwG_EPgsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65032b3d-3b5b-4d6a-9d6a-1019aa64bc8f"
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "dataset = loadtxt('labeled.csv', delimiter=',')\n",
        "\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:, 0:16]\n",
        "y = dataset[:, 16]\n",
        "\n",
        "# Define the keras model\n",
        "# Default activator: linear\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=16))\n",
        "model.add(Dense(4))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "# model.fit(X, y, epochs=100, batch_size=25)\n",
        "model.fit(X, y, epochs=100, batch_size=32)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy * 100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "338/338 [==============================] - 1s 1ms/step - loss: -2.3954 - accuracy: 0.3747\n",
            "Epoch 2/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5743 - accuracy: 0.3951\n",
            "Epoch 3/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.4893 - accuracy: 0.3990\n",
            "Epoch 4/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6682 - accuracy: 0.3991\n",
            "Epoch 5/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5875 - accuracy: 0.4012\n",
            "Epoch 6/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6966 - accuracy: 0.3960\n",
            "Epoch 7/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5555 - accuracy: 0.3984\n",
            "Epoch 8/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.4726 - accuracy: 0.3986\n",
            "Epoch 9/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5463 - accuracy: 0.4002\n",
            "Epoch 10/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6254 - accuracy: 0.4002\n",
            "Epoch 11/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6023 - accuracy: 0.3930\n",
            "Epoch 12/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7147 - accuracy: 0.4035\n",
            "Epoch 13/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6335 - accuracy: 0.3968\n",
            "Epoch 14/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5809 - accuracy: 0.4053\n",
            "Epoch 15/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5656 - accuracy: 0.3939\n",
            "Epoch 16/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5711 - accuracy: 0.3956\n",
            "Epoch 17/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5892 - accuracy: 0.3974\n",
            "Epoch 18/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7710 - accuracy: 0.3982\n",
            "Epoch 19/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9170 - accuracy: 0.3992\n",
            "Epoch 20/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6639 - accuracy: 0.3988\n",
            "Epoch 21/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8705 - accuracy: 0.3981\n",
            "Epoch 22/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5892 - accuracy: 0.4039\n",
            "Epoch 23/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5257 - accuracy: 0.3987\n",
            "Epoch 24/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9002 - accuracy: 0.3944\n",
            "Epoch 25/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6265 - accuracy: 0.4019\n",
            "Epoch 26/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7274 - accuracy: 0.3984\n",
            "Epoch 27/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5353 - accuracy: 0.3941\n",
            "Epoch 28/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7276 - accuracy: 0.3978\n",
            "Epoch 29/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8891 - accuracy: 0.3974\n",
            "Epoch 30/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5690 - accuracy: 0.3989\n",
            "Epoch 31/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7545 - accuracy: 0.3972\n",
            "Epoch 32/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8238 - accuracy: 0.3970\n",
            "Epoch 33/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7221 - accuracy: 0.4013\n",
            "Epoch 34/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7626 - accuracy: 0.3951\n",
            "Epoch 35/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5025 - accuracy: 0.3964\n",
            "Epoch 36/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8733 - accuracy: 0.3945\n",
            "Epoch 37/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8179 - accuracy: 0.4020\n",
            "Epoch 38/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6779 - accuracy: 0.3981\n",
            "Epoch 39/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6162 - accuracy: 0.3981\n",
            "Epoch 40/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7179 - accuracy: 0.4000\n",
            "Epoch 41/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8322 - accuracy: 0.3993\n",
            "Epoch 42/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6260 - accuracy: 0.4011\n",
            "Epoch 43/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6945 - accuracy: 0.3923\n",
            "Epoch 44/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8378 - accuracy: 0.3906\n",
            "Epoch 45/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6661 - accuracy: 0.4014\n",
            "Epoch 46/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8659 - accuracy: 0.4020\n",
            "Epoch 47/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7347 - accuracy: 0.3971\n",
            "Epoch 48/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6250 - accuracy: 0.3995\n",
            "Epoch 49/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7336 - accuracy: 0.3943\n",
            "Epoch 50/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5890 - accuracy: 0.3983\n",
            "Epoch 51/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8530 - accuracy: 0.3949\n",
            "Epoch 52/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5370 - accuracy: 0.4022\n",
            "Epoch 53/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6888 - accuracy: 0.3936\n",
            "Epoch 54/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7084 - accuracy: 0.3858\n",
            "Epoch 55/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8359 - accuracy: 0.3942\n",
            "Epoch 56/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7065 - accuracy: 0.3941\n",
            "Epoch 57/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6481 - accuracy: 0.3978\n",
            "Epoch 58/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7631 - accuracy: 0.3978\n",
            "Epoch 59/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8307 - accuracy: 0.3923\n",
            "Epoch 60/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6814 - accuracy: 0.4036\n",
            "Epoch 61/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8144 - accuracy: 0.4041\n",
            "Epoch 62/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8349 - accuracy: 0.3983\n",
            "Epoch 63/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7253 - accuracy: 0.4043\n",
            "Epoch 64/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7048 - accuracy: 0.3936\n",
            "Epoch 65/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8952 - accuracy: 0.3894\n",
            "Epoch 66/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6870 - accuracy: 0.3953\n",
            "Epoch 67/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9143 - accuracy: 0.3979\n",
            "Epoch 68/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.4748 - accuracy: 0.3999\n",
            "Epoch 69/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8255 - accuracy: 0.3947\n",
            "Epoch 70/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5545 - accuracy: 0.4013\n",
            "Epoch 71/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7625 - accuracy: 0.4006\n",
            "Epoch 72/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7396 - accuracy: 0.3979\n",
            "Epoch 73/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6765 - accuracy: 0.4047\n",
            "Epoch 74/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8113 - accuracy: 0.3987\n",
            "Epoch 75/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5207 - accuracy: 0.3997\n",
            "Epoch 76/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7509 - accuracy: 0.3983\n",
            "Epoch 77/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7525 - accuracy: 0.3980\n",
            "Epoch 78/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8462 - accuracy: 0.3990\n",
            "Epoch 79/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5517 - accuracy: 0.3997\n",
            "Epoch 80/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8414 - accuracy: 0.3928\n",
            "Epoch 81/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5111 - accuracy: 0.4107\n",
            "Epoch 82/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7410 - accuracy: 0.3968\n",
            "Epoch 83/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6578 - accuracy: 0.4029\n",
            "Epoch 84/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7475 - accuracy: 0.3984\n",
            "Epoch 85/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6931 - accuracy: 0.3969\n",
            "Epoch 86/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.4662 - accuracy: 0.4032\n",
            "Epoch 87/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6890 - accuracy: 0.4044\n",
            "Epoch 88/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6667 - accuracy: 0.3896\n",
            "Epoch 89/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6869 - accuracy: 0.4030\n",
            "Epoch 90/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8163 - accuracy: 0.3902\n",
            "Epoch 91/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5630 - accuracy: 0.4013\n",
            "Epoch 92/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7167 - accuracy: 0.4028\n",
            "Epoch 93/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6850 - accuracy: 0.3976\n",
            "Epoch 94/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7322 - accuracy: 0.4019\n",
            "Epoch 95/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8163 - accuracy: 0.3982\n",
            "Epoch 96/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7075 - accuracy: 0.3971\n",
            "Epoch 97/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7721 - accuracy: 0.4026\n",
            "Epoch 98/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7282 - accuracy: 0.3898\n",
            "Epoch 99/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7744 - accuracy: 0.3981\n",
            "Epoch 100/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6442 - accuracy: 0.4015\n",
            "338/338 [==============================] - 0s 832us/step - loss: -4.7019 - accuracy: 0.3987\n",
            "Accuracy: 39.87 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ujeOtt5Rv_o"
      },
      "source": [
        "**2) Single Hidden Layer ANN with Holdout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb-geYR8Ruv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33953aac-dca7-4351-9768-1bd40b4f515e"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from time import time\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13',\n",
        "             'att14', 'att15', 'att16', 'label']\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12',\n",
        "                'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols]\n",
        "y = DATA.label\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "\n",
        "test_start = time()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "clf = MLPClassifier(solver='adam', hidden_layer_sizes=(4,), max_iter=100, random_state=0)\n",
        "\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy + accuracy_score(y_test, y_pred)\n",
        "f1 = f1 + f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision + precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall + recall_score(y_test, y_pred, average='weighted')\n",
        "Confusion_Matrix = Confusion_Matrix + confusion_matrix(y_test, y_pred)\n",
        "test_finish = time()\n",
        "time = test_finish - test_start\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall Score:\", recall)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "\n",
        "print(\"Execution Time :\", (time * 10 * 10 * 10),\" milliseconds\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8166666666666667\n",
            "F1 Score: 0.7972044842952907\n",
            "Precision: 0.7793188737346011\n",
            "Recall Score: 0.8166666666666667\n",
            "       Confusion Matrix : \n",
            "[[169  86 106   0]\n",
            " [ 48 794   6   0]\n",
            " [ 59  10 801   0]\n",
            " [ 58  11  12   0]]\n",
            "Execution Time : 1825.3228664398193  milliseconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pahZfQVzSes7"
      },
      "source": [
        "**3) Single Hidden Layer ANN with Holdout and Bagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-MlOoEXSjJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234f1def-b97e-468d-a151-25dbc3863746"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "from sklearn.metrics import *\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13',\n",
        "             'att14', 'att15', 'att16', 'label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "# DATA.info()\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12',\n",
        "                'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols]  # Features\n",
        "y = DATA.label  # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "for x in range(1):\n",
        "    test_start = time()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=x)\n",
        "    ann = MLPClassifier(solver='adam', hidden_layer_sizes=(4, 1), max_iter=100, random_state=0)\n",
        "    model = BaggingClassifier(base_estimator=ann, n_estimators=10, random_state=1)\n",
        "    model = model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the response for test dataset\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy + accuracy_score(y_test, y_pred)\n",
        "    f1 = f1 + f1_score(y_test, y_pred, average='weighted')\n",
        "    precision = precision + precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall + recall_score(y_test, y_pred, average='weighted')\n",
        "    Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
        "    test_finish = time()\n",
        "    timee = timee + test_finish - test_start\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "\n",
        "print(\"Exec Time:\", ((timee) * 10 * 10 * 10), \" milliseconds\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmzfcATnt6B9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhhuxqxsUnoF"
      },
      "source": [
        "# ***Artificial Neural Networks (Dual Hidden Layer)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDVlSrndUrSS"
      },
      "source": [
        "1) Dual Hidden Layer ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED5n6PLJUxk3",
        "outputId": "18bd5393-3ab5-4056-f487-0031e72a58ae"
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# load the dataset\n",
        "dataset = loadtxt('labeled.csv', delimiter=',')\n",
        "\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:, 0:16]\n",
        "y = dataset[:, 16]\n",
        "\n",
        "# Define the keras model\n",
        "# Default activator: linear\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=16))\n",
        "model.add(Dense(8))\n",
        "model.add(Dense(4))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "# model.fit(X, y, epochs=100, batch_size=25)\n",
        "model.fit(X, y, epochs=100, batch_size=32)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy * 100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "338/338 [==============================] - 1s 1ms/step - loss: 2.1737 - accuracy: 0.3197\n",
            "Epoch 2/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.4630 - accuracy: 0.4049\n",
            "Epoch 3/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5581 - accuracy: 0.3938\n",
            "Epoch 4/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.4737 - accuracy: 0.4107\n",
            "Epoch 5/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8036 - accuracy: 0.3972\n",
            "Epoch 6/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6911 - accuracy: 0.4057\n",
            "Epoch 7/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7068 - accuracy: 0.4028\n",
            "Epoch 8/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7485 - accuracy: 0.3986\n",
            "Epoch 9/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8618 - accuracy: 0.3973\n",
            "Epoch 10/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7710 - accuracy: 0.3987\n",
            "Epoch 11/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8084 - accuracy: 0.4067\n",
            "Epoch 12/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6616 - accuracy: 0.4008\n",
            "Epoch 13/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7528 - accuracy: 0.3953\n",
            "Epoch 14/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8393 - accuracy: 0.4024\n",
            "Epoch 15/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9423 - accuracy: 0.3941\n",
            "Epoch 16/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5538 - accuracy: 0.4038\n",
            "Epoch 17/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7181 - accuracy: 0.4040\n",
            "Epoch 18/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5848 - accuracy: 0.4046\n",
            "Epoch 19/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7338 - accuracy: 0.3920\n",
            "Epoch 20/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6144 - accuracy: 0.4022\n",
            "Epoch 21/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6887 - accuracy: 0.4008\n",
            "Epoch 22/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6086 - accuracy: 0.4003\n",
            "Epoch 23/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7063 - accuracy: 0.4000\n",
            "Epoch 24/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7508 - accuracy: 0.3971\n",
            "Epoch 25/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5929 - accuracy: 0.4016\n",
            "Epoch 26/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6436 - accuracy: 0.3967\n",
            "Epoch 27/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7269 - accuracy: 0.3982\n",
            "Epoch 28/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.4949 - accuracy: 0.4011\n",
            "Epoch 29/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7211 - accuracy: 0.3959\n",
            "Epoch 30/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7861 - accuracy: 0.3955\n",
            "Epoch 31/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5376 - accuracy: 0.3946\n",
            "Epoch 32/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9017 - accuracy: 0.3973\n",
            "Epoch 33/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9253 - accuracy: 0.4028\n",
            "Epoch 34/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8982 - accuracy: 0.4003\n",
            "Epoch 35/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8674 - accuracy: 0.3992\n",
            "Epoch 36/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7530 - accuracy: 0.3936\n",
            "Epoch 37/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7908 - accuracy: 0.4008\n",
            "Epoch 38/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7069 - accuracy: 0.3911\n",
            "Epoch 39/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7065 - accuracy: 0.4016\n",
            "Epoch 40/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5802 - accuracy: 0.3973\n",
            "Epoch 41/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7941 - accuracy: 0.4021\n",
            "Epoch 42/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6833 - accuracy: 0.4034\n",
            "Epoch 43/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6020 - accuracy: 0.4002\n",
            "Epoch 44/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7189 - accuracy: 0.4036\n",
            "Epoch 45/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9174 - accuracy: 0.3967\n",
            "Epoch 46/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9421 - accuracy: 0.3916\n",
            "Epoch 47/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9071 - accuracy: 0.3929\n",
            "Epoch 48/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6444 - accuracy: 0.4060\n",
            "Epoch 49/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7170 - accuracy: 0.4044\n",
            "Epoch 50/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5899 - accuracy: 0.3979\n",
            "Epoch 51/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5710 - accuracy: 0.3991\n",
            "Epoch 52/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6488 - accuracy: 0.3952\n",
            "Epoch 53/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6702 - accuracy: 0.3973\n",
            "Epoch 54/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6637 - accuracy: 0.3956\n",
            "Epoch 55/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7605 - accuracy: 0.3954\n",
            "Epoch 56/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6228 - accuracy: 0.4026\n",
            "Epoch 57/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8452 - accuracy: 0.3921\n",
            "Epoch 58/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5545 - accuracy: 0.4037\n",
            "Epoch 59/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5474 - accuracy: 0.4012\n",
            "Epoch 60/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6030 - accuracy: 0.3998\n",
            "Epoch 61/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8043 - accuracy: 0.4045\n",
            "Epoch 62/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8168 - accuracy: 0.3962\n",
            "Epoch 63/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6395 - accuracy: 0.3948\n",
            "Epoch 64/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8208 - accuracy: 0.3940\n",
            "Epoch 65/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6341 - accuracy: 0.4036\n",
            "Epoch 66/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7454 - accuracy: 0.4004\n",
            "Epoch 67/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5924 - accuracy: 0.3939\n",
            "Epoch 68/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5546 - accuracy: 0.4054\n",
            "Epoch 69/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5260 - accuracy: 0.4033\n",
            "Epoch 70/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8550 - accuracy: 0.4037\n",
            "Epoch 71/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7260 - accuracy: 0.4110\n",
            "Epoch 72/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5812 - accuracy: 0.3955\n",
            "Epoch 73/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5539 - accuracy: 0.3975\n",
            "Epoch 74/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5296 - accuracy: 0.3994\n",
            "Epoch 75/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8144 - accuracy: 0.4003\n",
            "Epoch 76/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5877 - accuracy: 0.3985\n",
            "Epoch 77/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9217 - accuracy: 0.3922\n",
            "Epoch 78/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6534 - accuracy: 0.4001\n",
            "Epoch 79/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7404 - accuracy: 0.3974\n",
            "Epoch 80/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6628 - accuracy: 0.4083\n",
            "Epoch 81/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6058 - accuracy: 0.4002\n",
            "Epoch 82/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6775 - accuracy: 0.4059\n",
            "Epoch 83/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -5.0154 - accuracy: 0.3995\n",
            "Epoch 84/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6853 - accuracy: 0.3967\n",
            "Epoch 85/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7490 - accuracy: 0.4007\n",
            "Epoch 86/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7412 - accuracy: 0.3973\n",
            "Epoch 87/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.9752 - accuracy: 0.3855\n",
            "Epoch 88/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.7218 - accuracy: 0.3992\n",
            "Epoch 89/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6662 - accuracy: 0.3980\n",
            "Epoch 90/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6561 - accuracy: 0.3977\n",
            "Epoch 91/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6936 - accuracy: 0.3966\n",
            "Epoch 92/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5304 - accuracy: 0.4030\n",
            "Epoch 93/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6560 - accuracy: 0.3991\n",
            "Epoch 94/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6403 - accuracy: 0.3924\n",
            "Epoch 95/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5097 - accuracy: 0.4030\n",
            "Epoch 96/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6965 - accuracy: 0.3990\n",
            "Epoch 97/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5411 - accuracy: 0.4043\n",
            "Epoch 98/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.6848 - accuracy: 0.3899\n",
            "Epoch 99/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.5900 - accuracy: 0.4016\n",
            "Epoch 100/100\n",
            "338/338 [==============================] - 0s 1ms/step - loss: -4.8188 - accuracy: 0.3971\n",
            "338/338 [==============================] - 0s 954us/step - loss: -4.7019 - accuracy: 0.3987\n",
            "Accuracy: 39.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7lSq1tWc7oh"
      },
      "source": [
        "**2) Dual Hidden Layer ANN with Holdout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZI75RZ2dIf_",
        "outputId": "aa860f62-e9c7-44bb-98ee-f4f282074a97"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from time import time\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13',\n",
        "             'att14', 'att15', 'att16', 'label']\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12',\n",
        "                'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols]\n",
        "y = DATA.label\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "\n",
        "test_start = time()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "clf = MLPClassifier(solver='adam', hidden_layer_sizes=(8,4), max_iter=100, random_state=0)\n",
        "\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy + accuracy_score(y_test, y_pred)\n",
        "f1 = f1 + f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision + precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall + recall_score(y_test, y_pred, average='weighted')\n",
        "Confusion_Matrix = Confusion_Matrix + confusion_matrix(y_test, y_pred)\n",
        "test_finish = time()\n",
        "time = test_finish - test_start\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall Score:\", recall)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "\n",
        "print(\"Execution Time :\", (time * 10 * 10 * 10),\" milliseconds\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8314814814814815\n",
            "F1 Score: 0.8185808202728221\n",
            "Precision: 0.806699396150257\n",
            "Recall Score: 0.8314814814814815\n",
            "       Confusion Matrix : \n",
            "[[212  81  68   0]\n",
            " [ 59 788   1   0]\n",
            " [ 71   3 796   0]\n",
            " [ 69   8   4   0]]\n",
            "Execution Time : 8080.298185348511  milliseconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVm0VVsW8kHT"
      },
      "source": [
        "**3) Dual Hidden Layer ANN with Holdout and Bagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_9NnIkd8wD0",
        "outputId": "7535bbed-8e41-4e6a-d844-5aec1ad2ff58"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13',\n",
        "             'att14', 'att15', 'att16', 'label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "# DATA.info()\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12',\n",
        "                'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols]  # Features\n",
        "y = DATA.label  # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "for x in range(1):\n",
        "    test_start = time()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=x)\n",
        "    ann = MLPClassifier(solver='adam', hidden_layer_sizes=(8, 4), max_iter=100, random_state=0)\n",
        "    model = BaggingClassifier(base_estimator=ann, n_estimators=10, random_state=1)\n",
        "    model = model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the response for test dataset\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy + accuracy_score(y_test, y_pred)\n",
        "    f1 = f1 + f1_score(y_test, y_pred, average='weighted')\n",
        "    precision = precision + precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall + recall_score(y_test, y_pred, average='weighted')\n",
        "    Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
        "    test_finish = time()\n",
        "    timee = timee + test_finish - test_start\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "\n",
        "print(\"Exec Time:\", ((timee) * 10 * 10 * 10), \" milliseconds\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8458333333333333\n",
            "F1 Score: 0.8304971703243709\n",
            "Precision: 0.815846560327202\n",
            "Recall: 0.8458333333333333\n",
            "       Confusion Matrix : \n",
            "[[187  61  90   0]\n",
            " [ 40 799   9   0]\n",
            " [ 55   2 841   0]\n",
            " [ 65   1  10   0]]\n",
            "Exec Time: 23953.698873519897  milliseconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvJfTJHavlLF"
      },
      "source": [
        "# ***Ensembling Methods***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1JafrV3vx46"
      },
      "source": [
        "***1) Ensembling With Bagging Classifier Methods***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ2BftLuvs5u",
        "outputId": "6e7805b4-704c-4bb9-cc92-07b2c00b0251"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "x = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)\n",
        "\n",
        "# Instantiate models\n",
        "gnb = BaggingClassifier(base_estimator=GaussianNB(), n_estimators=10, random_state=0)\n",
        "SVM = BaggingClassifier(base_estimator=SVC(probability=True), n_estimators=10, random_state=0)\n",
        "dt = BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion=\"entropy\"), n_estimators=10, random_state=0)\n",
        "ANN_1 = BaggingClassifier(base_estimator = MLPClassifier(solver='adam', hidden_layer_sizes=(5, 1), max_iter=1000), n_estimators=10, random_state=0)\n",
        "\n",
        "\n",
        "# Define the list classifiers\n",
        "classifiers = [('Artifical Neural Network', ANN_1), ('Support Vector Machine', SVM),('Classification Tree', dt), ('Gaussian Naive Bayes', gnb)]\n",
        "\n",
        "# Iterate over the pre-defined list of classifiers\n",
        "#for clf_name, clf in classifiers:    \n",
        "    #_ = clf.fit(X_train, y_train)    \n",
        "    #y_pred = clf.predict(X_test)\n",
        "    #accuracy = accuracy_score(y_test, y_pred) \n",
        "    #print('{:s} : {:.3f}'.format(clf_name, accuracy))\n",
        "\n",
        "test_start = time()\n",
        "final_model = VotingClassifier(estimators=classifiers, voting='soft')     \n",
        "final_model.fit(X_train, y_train) \n",
        "\n",
        "y_pred = final_model.predict(X_test)\n",
        "test_finish = time() \n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
        "timee = test_finish-test_start\n",
        "\n",
        "#print('Voting Classifier: {:.3f}'.format(accuracy))\n",
        "print('Accuracy for voting classifier combined with bagging methods : ', accuracy)\n",
        "print('F1_score for voting classifier combined with bagging methods : ', f1)\n",
        "print('Precision score for voting classifier combined with bagging methods : ', precision)\n",
        "print('Recall for voting classifier combined with bagging methods : ', recall)\n",
        "print (\"         Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "print('Time required for voting classifier combined with bagging methods : ', timee, \" seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for voting classifier combined with bagging methods :  0.8472222222222222\n",
            "F1_score for voting classifier combined with bagging methods :  0.8319431926576162\n",
            "Precision score for voting classifier combined with bagging methods :  0.8371148767360922\n",
            "Recall for voting classifier combined with bagging methods :  0.8472222222222222\n",
            "         Confusion Matrix : \n",
            "[[197  81  99   2]\n",
            " [ 32 801   8   3]\n",
            " [ 30   8 814   0]\n",
            " [ 23  18  26  18]]\n",
            "Time required for voting classifier combined with bagging methods :  131.58692336082458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zATZQG3iv55_"
      },
      "source": [
        "***2) Ensembling With Boosting Classifier Methods***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMl1n_zGv6fu",
        "outputId": "86f47d0c-de03-4a80-e875-dc92ab6b06f7"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "x = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)\n",
        "\n",
        "# Instantiate models\n",
        "gnb = AdaBoostClassifier(base_estimator=GaussianNB(), n_estimators=10, random_state=0)\n",
        "dts = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion=\"gini\"), n_estimators=10, random_state=0)\n",
        "SVM = AdaBoostClassifier(base_estimator=SVC(probability=True), n_estimators=2, random_state=0)\n",
        "\n",
        "# Define the list classifiers\n",
        "classifiers = [('Support Vector Machine', SVM),('Classification Tree', dts), ('Gaussian Naive Bayes', gnb)]\n",
        "\n",
        "# Iterate over the pre-defined list of classifiers\n",
        "#for clf_name, clf in classifiers:    \n",
        "    #_ = clf.fit(X_train, y_train)    \n",
        "    #y_pred = clf.predict(X_test)\n",
        "    #accuracy = accuracy_score(y_test, y_pred) \n",
        "    #print('{:s} : {:.3f}'.format(clf_name, accuracy))\n",
        "\n",
        "test_start = time()\n",
        "final_model = VotingClassifier(estimators=classifiers, voting='soft')     \n",
        "final_model.fit(X_train, y_train) \n",
        "\n",
        "y_pred = final_model.predict(X_test)\n",
        "test_finish = time() \n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
        "timee = test_finish-test_start\n",
        "\n",
        "#print('Voting Classifier: {:.3f}'.format(accuracy))\n",
        "print('Accuracy for voting classifier combined with boosting methods : ', accuracy)\n",
        "print('F1_score for voting classifier combined with boosting methods : ', f1)\n",
        "print('Precision score for voting classifier combined with boosting methods : ', precision)\n",
        "print('Recall for voting classifier combined with boosting methods : ', recall)\n",
        "print (\"         Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "print('Time required for voting classifier combined with boosting methods : ', timee, \" seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for voting classifier combined with boosting methods :  0.7421296296296296\n",
            "F1_score for voting classifier combined with boosting methods :  0.7455377727969071\n",
            "Precision score for voting classifier combined with boosting methods :  0.7494601031879936\n",
            "Recall for voting classifier combined with boosting methods :  0.7421296296296296\n",
            "         Confusion Matrix : \n",
            "[[186  80 100  13]\n",
            " [ 99 684  24  37]\n",
            " [ 94  24 707  27]\n",
            " [ 14  23  22  26]]\n",
            "Time required for voting classifier combined with boosting methods :  61.37003183364868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0NRE6jhXNvX"
      },
      "source": [
        "***3) Ensembling With Best Accuracy Classifiers Method***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VgRUQLlXTnL",
        "outputId": "4ca68ea7-e752-4ded-8420-b585e4ee1c2a"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "x = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)\n",
        "\n",
        "# Instantiate models\n",
        "gnb = AdaBoostClassifier(base_estimator=GaussianNB(), n_estimators=10, random_state=0)\n",
        "dts = BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion=\"entropy\"), n_estimators=10, random_state=0)\n",
        "SVM = SVC(probability=True)\n",
        "ANN_1 = BaggingClassifier(base_estimator = MLPClassifier(solver='adam', hidden_layer_sizes=(8,4), max_iter=1000), n_estimators=10, random_state=0)\n",
        "\n",
        "# Define the list classifiers\n",
        "classifiers = [('Support Vector Machine', SVM), ('Artifical Neural Network', ANN_1), ('Classification Tree', dt), ('Gaussian Naive Bayes', gnb)]\n",
        "\n",
        "# Iterate over the pre-defined list of classifiers\n",
        "#for clf_name, clf in classifiers:    \n",
        "    #_ = clf.fit(X_train, y_train)    \n",
        "    #y_pred = clf.predict(X_test)\n",
        "    #accuracy = accuracy_score(y_test, y_pred) \n",
        "    #print('{:s} : {:.3f}'.format(clf_name, accuracy))\n",
        "\n",
        "test_start = time()\n",
        "final_model = VotingClassifier(estimators=classifiers, voting='soft')     \n",
        "final_model.fit(X_train, y_train) \n",
        "\n",
        "y_pred = final_model.predict(X_test)\n",
        "test_finish = time() \n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "Confusion_Matrix = confusion_matrix(y_test, y_pred)\n",
        "timee = test_finish-test_start\n",
        "\n",
        "#print('Voting Classifier: {:.3f}'.format(accuracy))\n",
        "print('Accuracy for voting classifier combined with best methods : ', accuracy)\n",
        "print('F1_score for voting classifier combined with best methods : ', f1)\n",
        "print('Precision score for voting classifier combined with best methods : ', precision)\n",
        "print('Recall for voting classifier combined with best methods : ', recall)\n",
        "print (\"         Confusion Matrix : \")\n",
        "print(Confusion_Matrix)\n",
        "print('Time required for voting classifier combined with best methods : ', timee, \" seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for voting classifier combined with best methods :  0.8546296296296296\n",
            "F1_score for voting classifier combined with best methods :  0.8471829274845076\n",
            "Precision score for voting classifier combined with best methods :  0.8476163377774618\n",
            "Recall for voting classifier combined with best methods :  0.8546296296296296\n",
            "         Confusion Matrix : \n",
            "[[222  66  89   2]\n",
            " [ 43 788   7   6]\n",
            " [ 41   7 803   1]\n",
            " [ 18  17  17  33]]\n",
            "Time required for voting classifier combined with best methods :  93.20690989494324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi4NmRP5-xaj"
      },
      "source": [
        "# Yeni Blm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oZhEOWs-3Z7"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn.metrics import *\n",
        "from time import time\n",
        "\n",
        "col_names = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16','label']\n",
        "# load dataset\n",
        "DATA = pd.read_csv(\"Final_Data.csv\", header=None, names=col_names)\n",
        "\n",
        "#DATA.info()\n",
        "feature_cols = ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16']\n",
        "\n",
        "X = DATA[feature_cols] # Features\n",
        "y = DATA.label # Target variable\n",
        "\n",
        "accuracy = 0\n",
        "Confusion_Matrix = 0\n",
        "f1 = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "timee = 0\n",
        "\n",
        "for x in range(10):\n",
        "  test_start = time()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=x) # 80% training and 20% test\n",
        "\n",
        "  # Create Decision Tree classifer object\n",
        "  clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "\n",
        "  # Train Decision Tree Classifer\n",
        "  clf = clf.fit(X_train, y_train)\n",
        "\n",
        "  #Predict the response for test dataset\n",
        "  y_pred = clf.predict(X_test)\n",
        "  \n",
        "  accuracy = accuracy + accuracy_score(y_test, y_pred)\n",
        "  f1 = f1 + f1_score(y_test, y_pred, average='weighted')\n",
        "  precision = precision + precision_score(y_test, y_pred, average='weighted')\n",
        "  recall = recall + recall_score(y_test, y_pred, average='weighted')\n",
        "  Confusion_Matrix = Confusion_Matrix + confusion_matrix(y_test, y_pred)\n",
        "  test_finish = time()\n",
        "  timee = timee + test_finish-test_start\n",
        "\n",
        "print(\"Overall accuracy for decision tree with gain ratio and hold out method(10 times) :\", accuracy/10)\n",
        "print(\"Overall f1_score for decision tree with gain ratio and hold out method(10 times) :\", f1/10)\n",
        "print(\"Overall precision_score for decision tree with gain ratio and hold out method(10 times) :\", precision/10)\n",
        "print(\"Overall recall_score for decision tree with gain ratio and hold out method(10 times) :\", recall/10)\n",
        "\n",
        "print(\"       Confusion Matrix : \")\n",
        "print(Confusion_Matrix/10)\n",
        "\n",
        "print(\"Overall time needed for decision tree with gain ratio and hold out method(10 times) :\", ((timee/10)*10*10*10), \" miliseconds\")"
      ]
    }
  ]
}